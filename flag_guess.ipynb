{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choobrendan/Flag-Guesser/blob/main/flag_guess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NYxzpxVT9y4d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.layers import LeakyReLU\n",
        "from PIL import Image\n",
        "keras = tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jYIZAjwATb-",
        "outputId": "f8adc021-3e6a-453a-d6bf-3ea6369dedcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hHrNnpwAl2e",
        "outputId": "d3fcd2a1-ee0d-429d-8274-5cb1072f9722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content/Flags.zip'\n",
            "Try 'cp --help' for more information.\n",
            "unzip:  cannot find or open PetImages.zip, PetImages.zip.zip or PetImages.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!cp  /content/Flags.zip\n",
        "!unzip PetImages.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J6gccCdh9y4f"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('CPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkewILy09y4f",
        "outputId": "9ef1aa22-04e2-4f87-b11b-b508d0eef698"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BrMVhabw9y4g"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices ('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth (gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-DesFyE19y4g"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imghdr\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_SI4_K4T9y4g"
      },
      "outputs": [],
      "source": [
        "data_dir=r\"/content/drive/MyDrive/Flags\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sWBSsKH59y4h"
      },
      "outputs": [],
      "source": [
        "from struct import unpack\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "marker_mapping = {\n",
        "    0xffd8: \"Start of Image\",\n",
        "    0xffe0: \"Application Default Header\",\n",
        "    0xffdb: \"Quantization Table\",\n",
        "    0xffc0: \"Start of Frame\",\n",
        "    0xffc4: \"Define Huffman Table\",\n",
        "    0xffda: \"Start of Scan\",\n",
        "    0xffd9: \"End of Image\"\n",
        "}\n",
        "\n",
        "\n",
        "class JPEG:\n",
        "    def __init__(self, image_file):  # Fix the method name here\n",
        "        with open(image_file, 'rb') as f:\n",
        "            self.img_data = f.read()\n",
        "\n",
        "    def decode(self):\n",
        "        data = self.img_data\n",
        "        while(True):\n",
        "            marker, = unpack(\">H\", data[0:2])\n",
        "            # print(marker_mapping.get(marker))\n",
        "            if marker == 0xffd8:\n",
        "                data = data[2:]\n",
        "            elif marker == 0xffd9:\n",
        "                return\n",
        "            elif marker == 0xffda:\n",
        "                data = data[-2:]\n",
        "            else:\n",
        "                lenchunk, = unpack(\">H\", data[2:4])\n",
        "                data = data[2+lenchunk:]\n",
        "            if len(data)==0:\n",
        "                break\n",
        "\n",
        "\n",
        "bads = []\n",
        "\n",
        "for image_class in os.listdir(data_dir):\n",
        "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "        image_path = os.path.join(data_dir, image_class, image)\n",
        "        image = JPEG(image_path)\n",
        "        try:\n",
        "          image.decode()\n",
        "        except:\n",
        "          bads.append(image_path)\n",
        "          print(image_path)\n",
        "\n",
        "\n",
        "for name in bads:\n",
        "  try:\n",
        "    os.remove(image_path)\n",
        "  except Exception:\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TZtOuH1A9y4g"
      },
      "outputs": [],
      "source": [
        "image_exts=[\"jpeg\",\"jpg\",\"bmp\",\"png\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DYDbV0XM9y4g"
      },
      "outputs": [],
      "source": [
        "num_classes=len(os.listdir(r\"/content/drive/MyDrive/Flags\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gdHbGN49y4g",
        "outputId": "60001994-694b-4ef9-bd84-255f19bac873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector5.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector5.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector6.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector6.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector7.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector7.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector3.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector3.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector2.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector2.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector4.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector4.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector17.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector17.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector11.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector11.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector10.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector10.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector16.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector16.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector15.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector15.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector9.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector9.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector12.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector12.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector13.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector13.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector18.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector18.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector14.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector14.svg\n",
            "Image not in ext list /content/drive/MyDrive/Flags/Belize/vector8.svg\n",
            "Issue with image /content/drive/MyDrive/Flags/Belize/vector8.svg\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def convert_to_png(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    new_image_path = os.path.splitext(image_path)[0] + \".png\"\n",
        "    img.save(new_image_path, \"PNG\")\n",
        "    os.remove(image_path)  # Remove the original non-image file\n",
        "\n",
        "for image_class in os.listdir(data_dir):\n",
        "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "        image_path = os.path.join(data_dir, image_class, image)\n",
        "        try:\n",
        "            tip = imghdr.what(image_path)\n",
        "            if tip not in image_exts:\n",
        "                print('Image not in ext list {}'.format(image_path))\n",
        "                convert_to_png(image_path)\n",
        "        except (IOError, OSError) as e:\n",
        "            print('Issue with image {}'.format(image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ss_CmHnN9y4h"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    zoom_range=0.2,         # Randomly zoom images by 20%\n",
        "    width_shift_range=0.1,  # Randomly shift images horizontally by 10%\n",
        "    height_shift_range=0.1, # Randomly shift images vertically by 10%\n",
        "    rotation_range=5,      # Randomly rotate images by up to 20 degrees\n",
        "    brightness_range=(0.7, 1.3),  # Randomly adjust brightness between 0.8 and 1.2\n",
        "    shear_range=0.2,        # Randomly apply shearing transformations\n",
        "    horizontal_flip=False,   # Randomly flip images horizontally\n",
        "    vertical_flip=False      # Randomly flip images vertically\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-LWf_nG-9y4h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKhUzjV89y4h",
        "outputId": "7393a29e-50fc-4c74-be2a-d19b97d59c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13863 files belonging to 80 classes.\n"
          ]
        }
      ],
      "source": [
        "data = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    label_mode='categorical',  # This indicates multiclass classification\n",
        "    seed=42,  # Set the seed for reproducibility\n",
        "    image_size=(256, 256),\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dAnYVDYr9y4h"
      },
      "outputs": [],
      "source": [
        "data=data.map(lambda x,y:(x/255,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7pYfoAs59y4i"
      },
      "outputs": [],
      "source": [
        "scaled_iterator=data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TbSJXed09y4i"
      },
      "outputs": [],
      "source": [
        "batch=scaled_iterator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F-my0xiD9y4i"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data) * 0.7)\n",
        "val_size = int(len(data) * 0.15)\n",
        "test_size = int(len(data) * 0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "h_QHQpAt9y4i"
      },
      "outputs": [],
      "source": [
        "train=data.take (train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test=data.skip (train_size+val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YlXy2koq9y4i"
      },
      "outputs": [],
      "source": [
        "# def preprocess_image(image_path):\n",
        "#     img = cv2.imread(image_path)\n",
        "#     tip = imghdr.what(image_path)\n",
        "#     if tip not in image_exts:\n",
        "#         print('Image not in ext list {}'.format(image_path))\n",
        "#         os.remove(image_path)\n",
        "#         return None\n",
        "#     # Convert to 8-bit unsigned integers\n",
        "#     img = cv2.convertScaleAbs(img)\n",
        "#     return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_t_VCwo89y4i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the data augmentation function\n",
        "def augment_image(image, label):\n",
        "    # Randomly adjust brightness, contrast, saturation, and hue\n",
        "    image = tf.image.random_brightness(image, max_delta=0.02)\n",
        "    image = tf.image.random_contrast(image, lower=0.99, upper=1.01)\n",
        "    image = tf.image.random_saturation(image, lower=0.99, upper=1.01)\n",
        "    image = tf.image.random_hue(image, max_delta=0.01)\n",
        "    # Add more augmentation techniques as per your requirement\n",
        "    # For example, you can use tf.image.random_flip_left_right for random horizontal flipping, etc.\n",
        "\n",
        "    return image, label\n",
        "\n",
        "# Define the preprocess function without resizing to use it later for validation and test sets\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)  # Convert to 8-bit unsigned int\n",
        "    image = tf.image.resize(image, (256, 256))\n",
        "    image =image/255.0# Resize to model input size\n",
        "    return image, label\n",
        "\n",
        "# # Apply duplication and augmentation to the training data\n",
        "# def augment_and_duplicate(image, label, num_duplicates=1):\n",
        "#     # List to store augmented images and labels\n",
        "#     augmented_images = []\n",
        "#     augmented_labels = []\n",
        "\n",
        "#     # Add original image and label to the lists\n",
        "#     augmented_images.append(image)\n",
        "#     augmented_labels.append(label)\n",
        "\n",
        "#     # Apply augmentation and add duplicates to the lists\n",
        "#     for _ in range(num_duplicates):\n",
        "#         augmented_image, augmented_label = augment_image(image, label)\n",
        "#         augmented_images.append(augmented_image)\n",
        "#         augmented_labels.append(augmented_label)\n",
        "\n",
        "#     # Stack the lists to create tensors\n",
        "#     augmented_images = tf.stack(augmented_images)\n",
        "#     augmented_labels = tf.stack(augmented_labels)\n",
        "\n",
        "#     return augmented_images, augmented_labels\n",
        "\n",
        "# # Duplicate and augment the training data\n",
        "# num_duplicates = 2 # You can adjust the number of duplicates as per your requirement\n",
        "# train = train.flat_map(lambda image, label: tf.data.Dataset.from_tensor_slices(augment_and_duplicate(image, label, num_duplicates)))\n",
        "train = train.map(preprocess_image)\n",
        "# Apply preprocessing to validation and test sets\n",
        "val = val.map(preprocess_image)\n",
        "test = test.map(preprocess_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ldskap8-9y4j"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (9, 9), 1, activation=keras.layers.LeakyReLU(alpha=0.2), input_shape=(256, 256, 3)))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "\n",
        "# Second convolution layer with increased filters, Dropout, and Regularization\n",
        "model.add(Conv2D(64, (7, 7), strides=1, activation=keras.layers.LeakyReLU(alpha=0.15), kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# Third convolution layer with increased filters and BatchNormalization\n",
        "model.add(Conv2D(64, (5, 5), strides=1, activation=keras.layers.LeakyReLU(alpha=0.10), kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# Third convolution layer with increased filters and BatchNormalization\n",
        "model.add(Conv2D(32, (3, 3), strides=1, activation=keras.layers.LeakyReLU(alpha=0.05), kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# Flatten the output to feed into the dense layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense layers with Dropout and Regularization\n",
        "model.add(Dense(256, activation=keras.layers.LeakyReLU(alpha=0.02), kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer for multiclass classification\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=30,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'],)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P6Bwwm49y4j",
        "outputId": "51a3233d-9806-4c7c-f173-24bf4edea5fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 248, 248, 32)      7808      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 124, 124, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 118, 118, 64)      100416    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 118, 118, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 59, 59, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 55, 55, 64)        102464    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 55, 55, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 27, 27, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 25, 25, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 25, 25, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 12, 12, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1179904   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 80)                20560     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,430,000\n",
            "Trainable params: 1,429,808\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Yx4NPz659y4j"
      },
      "outputs": [],
      "source": [
        "logdir='logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChkD8VxZMtg_",
        "outputId": "e81aa634-1252-4083-df8a-7afe6569f84e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "303/303 [==============================] - 152s 466ms/step - loss: 6.7728 - accuracy: 0.5361 - val_loss: 3.9572 - val_accuracy: 0.7654\n",
            "Epoch 2/500\n",
            "303/303 [==============================] - 154s 505ms/step - loss: 3.1633 - accuracy: 0.7369 - val_loss: 2.2643 - val_accuracy: 0.8139\n",
            "Epoch 3/500\n",
            "303/303 [==============================] - 139s 452ms/step - loss: 2.2185 - accuracy: 0.7922 - val_loss: 1.8310 - val_accuracy: 0.8630\n",
            "Epoch 4/500\n",
            "303/303 [==============================] - 141s 461ms/step - loss: 1.9680 - accuracy: 0.8098 - val_loss: 1.8778 - val_accuracy: 0.8356\n",
            "Epoch 5/500\n",
            "303/303 [==============================] - 154s 506ms/step - loss: 1.9011 - accuracy: 0.8241 - val_loss: 2.3914 - val_accuracy: 0.6817\n",
            "Epoch 6/500\n",
            "303/303 [==============================] - 155s 508ms/step - loss: 1.7877 - accuracy: 0.8430 - val_loss: 1.7274 - val_accuracy: 0.8668\n",
            "Epoch 7/500\n",
            "303/303 [==============================] - ETA: 0s - loss: 1.7526 - accuracy: 0.8564"
          ]
        }
      ],
      "source": [
        "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "hist=model.fit(train, epochs=500, validation_data=val, callbacks =[tensorboard_callback,early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tM3CQvw9y4j",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "# Assuming you have already trained the model and have the test dataset\n",
        "# (or you can use 'test' set if you have already created it)\n",
        "\n",
        "# Get the true labels and predicted labels from the test set\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for images, labels in test:\n",
        "    y_true.extend(np.argmax(labels, axis=1))  # Get the true class indices\n",
        "    y_pred.extend(np.argmax(model.predict(images), axis=1))  # Get the predicted class indices\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Normalize the confusion matrix to show probabilities instead of counts\n",
        "conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "class_names = os.listdir(r\"/content/drive/MyDrive/Flags\")\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(40, 32))\n",
        "sns.heatmap(conf_matrix_norm, annot=True, cmap=\"Blues\", fmt=\".2f\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Probabilities')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "# If you want a classification report (precision, recall, F1-score, etc.), you can use the following:\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tipE4SwM9y4k"
      },
      "outputs": [],
      "source": [
        "new_image_path = r\"/content/sample_data/TestImage.jpg\"  # Replace with the path to your new image\n",
        "\n",
        "i=23\n",
        "# Load and preprocess the new image\n",
        "new_image = cv2.imread(new_image_path)\n",
        "new_image = cv2.convertScaleAbs(new_image)\n",
        "new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
        "new_image = tf.image.convert_image_dtype(new_image, dtype=tf.uint8)\n",
        "resize= tf.image.resize(new_image,(256,256))\n",
        "# new_image = new_image / 255.0  # Normalize pixel values to [0, 1]\n",
        "predictions=model.predict(np.expand_dims(resize,axis=0))\n",
        "# Convert the image to a supported depth (e.g., 8-bit unsigned integers)\n",
        "\n",
        "#  # Add batch dimension\n",
        "\n",
        "# View the new image\n",
        "plt.imshow(new_image.numpy().squeeze())\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "predicted_class_index = np.argmax(predictions[0])\n",
        "predicted_class_name = predicted_class_name = sorted(os.listdir(r\"/content/drive/MyDrive/Flags\"))[predicted_class_index] # Assuming class indices are integers starting from 0\n",
        "\n",
        "# Print the predicted class index and name\n",
        "print(\"Predicted Class Index:\", predicted_class_index)\n",
        "print(\"Predicted Class Name:\", predicted_class_name)\n",
        "print(\"Predicted Class Confidence:\", predictions[0][np.argmax(predictions[0])])\n",
        "predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8zdyZXA9y4k"
      },
      "outputs": [],
      "source": [
        "a=os.listdir(r\"/kaggle/input/flag-pictures-dataset/Flags\")\n",
        "sorted(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVbZ_HMe9y4k"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfLiE7Gf9y4k"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "batch[2][31]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cQ3ruTL9y4k"
      },
      "outputs": [],
      "source": [
        "new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-myt0Eid9y4k"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Convert the image to a supported depth (e.g., 8-bit unsigned integers)\n",
        "image = cv2.convertScaleAbs((new_image/(255)).numpy(), alpha=(255.0))\n",
        "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "# View the new image\n",
        "plt.imshow(cv2.cvtColor(image.squeeze(), cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pxsj07V9y4k"
      },
      "outputs": [],
      "source": [
        "model.save(r\"/content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVq8OauaqvJb"
      },
      "outputs": [],
      "source": [
        "modelsaved = tf.keras.models.load_model(r\"/content/sequential_3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_KemaZOq0mN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNzBmGyZrnkK"
      },
      "outputs": [],
      "source": [
        "%cd /content/sequential_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAye-ymjrsdM"
      },
      "outputs": [],
      "source": [
        "!zip -r sequential_3.zip /content/sequential_3/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9qhEyJRsAxb"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(r'/content/sequential_3/sequential_3.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}